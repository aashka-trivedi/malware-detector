{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malware Detector\n",
    "\n",
    "Final Model for our Malware Detector. \n",
    "\n",
    "Data and feature Analysis: Data_Feature_Analysis.ipynb\n",
    "\n",
    "Model Testing and Tuning: Model_Tuning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('top_1000_pe_imports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= data[['OpenProcess', 'LoadLibraryA', 'GetProcessHeap', 'ShellExecuteW', 'VirtualFree', 'GetDC', 'IsDebuggerPresent', 'malloc', 'FindNextFileA', 'free', 'GetAsyncKeyState', 'GetTickCount', 'exit', '_cexit', 'VirtualAlloc', 'VirtualProtect', 'GetModuleHandleA', 'ExitProcess', 'RegCloseKey','GetCurrentProcessId', 'malware']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47580, 20) (47580,)\n"
     ]
    }
   ],
   "source": [
    "y= df['malware']\n",
    "X= df.drop(['malware'], axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "#print(X_train.shape, X_test.shape)\n",
    "#print(y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=110, max_features=3,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=3,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=3, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "                            random_state=3, \n",
    "                            bootstrap= True,\n",
    "                            max_depth= 110,\n",
    "                            max_features= 3,\n",
    "                            min_samples_leaf= 2,\n",
    "                            min_samples_split= 3)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "#If Bootstrap is False then OOB is not available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9774064733081127\n",
      "Test Accuracy: 0.976881042454813\n"
     ]
    }
   ],
   "source": [
    "y_pred= rf.predict(X_test)\n",
    "\n",
    "print(\"Train Accuracy:\",rf.score(X_train, y_train) )#accuracy\n",
    "print( \"Test Accuracy:\", accuracy_score(y_test, y_pred, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.97372915 0.977013   0.97583082 0.97596217 0.97792958]\n",
      "Mean:  0.976092944426241\n",
      "Standard Deviation:  0.0014066347881113428\n"
     ]
    }
   ],
   "source": [
    "scores= cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy') #5 fold\n",
    "\n",
    "print(\"Scores: \", scores)\n",
    "print(\"Mean: \", scores.mean())\n",
    "print(\"Standard Deviation: \", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, X_val, y_val, predictions):\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(y_val, predictions))\n",
    "    print(\"Precision:\", precision_score(y_val, predictions))\n",
    "    print(\"Recall:\",recall_score(y_val, predictions))\n",
    "    print(\"F1 Score:\", f1_score(y_val, predictions))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Evaluation:\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  705   827]\n",
      " [  113 36419]]\n",
      "Precision: 0.9777962734253343\n",
      "Recall: 0.9969068214168401\n",
      "F1 Score: 0.9872590745208598\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation Evaluation\n",
    "\n",
    "print(\"Cross Validation Evaluation:\\n\")\n",
    "predictions = cross_val_predict(rf, X_train, y_train, cv=3)\n",
    "evaluation(rf, X_train, y_train, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set Evaluation:\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 213  184]\n",
      " [  36 9083]]\n",
      "Precision: 0.9801445991151397\n",
      "Recall: 0.9960521987059985\n",
      "F1 Score: 0.9880343739802023\n"
     ]
    }
   ],
   "source": [
    "#Test Set Evaulation\n",
    "\n",
    "print(\"\\nTest Set Evaluation:\\n\")\n",
    "y_pred = rf.predict(X_test)\n",
    "evaluation(rf, X_test, y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

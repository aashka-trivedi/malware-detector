{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malware Detector: Testing and Tuning the Model\n",
    "\n",
    "Features by Bhat\n",
    "Final Model: Malware_Detector.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('/data/top_1000_pe_imports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= data[['OpenProcess', 'GetCurrentProcess', 'GetProcessHeap','ReadFile', 'CreateFileW', 'WriteFile', 'FindFirstFileW', 'FindNextFileW', 'SetWindowsHookExW', 'GetAsyncKeyState', 'GetForegroundWindow', 'GetKeyState', 'MapVirtualKeyW', 'VirtualAlloc', 'VirtualProtect', 'GetModuleHandleA', 'ExitProcess', 'RegCloseKey','GetCurrentProcessId', 'malware']]\n",
    "#df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47580, 19) (47580,)\n"
     ]
    }
   ],
   "source": [
    "y= df['malware']\n",
    "X= df.drop(['malware'], axis=1)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=2)\n",
    "#print(X_train.shape, X_test.shape)\n",
    "#print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                       n_jobs=None, oob_score=False, random_state=3, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=3)\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9781158049600672\n",
      "Test Accuracy: 0.9747793190416141\n"
     ]
    }
   ],
   "source": [
    "y_pred= rf.predict(X_test)\n",
    "\n",
    "print(\"Train Accuracy:\",rf.score(X_train, y_train) )\n",
    "print( \"Test Accuracy:\", accuracy_score(y_test, y_pred, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:  [0.97202154 0.97267831 0.97202154 0.97162748 0.9737257 ]\n",
      "Mean:  0.972414914638021\n",
      "Standard Deviation:  0.0007371656123245062\n"
     ]
    }
   ],
   "source": [
    "#since accuracy is pretty high (97.8%), will check on cross validation\n",
    "\n",
    "scores= cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy') #5 fold\n",
    "\n",
    "print(\"Scores: \", scores)\n",
    "print(\"Mean: \", scores.mean())\n",
    "print(\"Standard Deviation: \", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score: 97.28999999999999 %\n"
     ]
    }
   ],
   "source": [
    "#Still pretty good accuracy, so checking Out of Bag score\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, oob_score = True, random_state=3)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"OOB score:\", round(rf.oob_score_, 4)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, X_val, y_val, predictions):\n",
    "    print(\"Confusion Matrix: \\n\", confusion_matrix(y_val, predictions))\n",
    "    print(\"Precision:\", precision_score(y_val, predictions))\n",
    "    print(\"Recall:\",recall_score(y_val, predictions))\n",
    "    print(\"F1 Score:\", f1_score(y_val, predictions))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation:\n",
      "\n",
      "Confusion Matrix: \n",
      " [[  639   893]\n",
      " [  183 36349]]\n",
      "Precision: 0.9760216959346973\n",
      "Recall: 0.9949906930909888\n",
      "F1 Score: 0.985414915824003\n"
     ]
    }
   ],
   "source": [
    "#Cross Val Evaluation\n",
    "\n",
    "print(\"Cross Validation:\\n\")\n",
    "predictions = cross_val_predict(rf, X_train, y_train, cv=3)\n",
    "evaluation(rf, X_train, y_train, predictions)\n",
    "\n",
    "\n",
    "#Confusion matrix: [[TN, FP], [FN,TP]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set:\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 201  196]\n",
      " [  44 9075]]\n",
      "Precision: 0.9788588070326826\n",
      "Recall: 0.9951749095295537\n",
      "F1 Score: 0.9869494290375205\n"
     ]
    }
   ],
   "source": [
    "#Testing Evaluation\n",
    "\n",
    "print(\"Test Set:\\n\")\n",
    "y_pred = rf.predict(X_test)\n",
    "evaluation(rf, X_test, y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "High Precision= Low false positive rate\n",
    "\n",
    "High Recall= Low false negative rate\n",
    "\n",
    "So I am seeing some false positives. But good news is that we have VVV high true positives and VVV low false negatives, which is required for a Malware Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Feature</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GetCurrentProcessId</th>\n",
       "      <td>0.143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExitProcess</th>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GetModuleHandleA</th>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GetCurrentProcess</th>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VirtualProtect</th>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VirtualAlloc</th>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WriteFile</th>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GetProcessHeap</th>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RegCloseKey</th>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GetAsyncKeyState</th>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreateFileW</th>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OpenProcess</th>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReadFile</th>\n",
       "      <td>0.034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FindNextFileW</th>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FindFirstFileW</th>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GetForegroundWindow</th>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MapVirtualKeyW</th>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GetKeyState</th>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SetWindowsHookExW</th>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Importance\n",
       "Feature                        \n",
       "GetCurrentProcessId       0.143\n",
       "ExitProcess               0.120\n",
       "GetModuleHandleA          0.095\n",
       "GetCurrentProcess         0.073\n",
       "VirtualProtect            0.062\n",
       "VirtualAlloc              0.058\n",
       "WriteFile                 0.052\n",
       "GetProcessHeap            0.051\n",
       "RegCloseKey               0.049\n",
       "GetAsyncKeyState          0.047\n",
       "CreateFileW               0.040\n",
       "OpenProcess               0.039\n",
       "ReadFile                  0.034\n",
       "FindNextFileW             0.028\n",
       "FindFirstFileW            0.027\n",
       "GetForegroundWindow       0.024\n",
       "MapVirtualKeyW            0.022\n",
       "GetKeyState               0.020\n",
       "SetWindowsHookExW         0.016"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking what Features are deamed important by the classifier; cross check with how it relates to Bhat's Stuff\n",
    "\n",
    "importances= pd.DataFrame({'Feature': X_train.columns, 'Importance': np.round(rf.feature_importances_,3)})\n",
    "importances= importances.sort_values('Importance', ascending=False).set_index('Feature')\n",
    "\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 50,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': True,\n",
      " 'random_state': 3,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Current parameters in use\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters I want to work on:\n",
    "1. bootstrap = method for sampling data points (with or without replacement) (False= entire dataset used to make trees)\n",
    "2. max_depth = max number of levels in each decision tree  (More depth may lead to single leaf nodes in each tree, less depth may not be sufficient enough to capture the info)\n",
    "3. max_features = max number of features considered for splitting a node\n",
    "4. n_estimators = number of trees in the forest \n",
    "5. min_samples_split = min number of data points placed in a node before the node is split (how many samples are needed to split the node)\n",
    "6. min_samples_leaf = min number of data points allowed in a leaf node (helps smoothen the model)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing diff values: each iteration, algo chooses a different combination of features\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier() #Base Model\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               random_state=42,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "# 3 folds of cross validation, more cv reduces overfitting but increases run time.\n",
    "# n_jobs=-1 uses all processors in parallel\n",
    "# Verbosity helps log the output. https://stats.stackexchange.com/questions/153823/what-is-verbose-in-scikit-learn-package-of-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show best parameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found Best Parameters:\n",
    "\n",
    "1. n_estimators: 1000\n",
    "2. min_smaples_split: 5\n",
    "3. min_samples_leaf: 2\n",
    "4. max_features: sqrt\n",
    "5. max_depth: 100\n",
    "6. bootstrap: False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'n_estimators': [800, 900, 100]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters:\n",
    " 1. 'bootstrap': False,\n",
    " 2. 'max_depth': 110,\n",
    " 3. 'max_features': 3,\n",
    " 4. 'min_samples_leaf': 2,\n",
    " 5. 'min_samples_split': 3,\n",
    " 6. 'n_estimators': 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
